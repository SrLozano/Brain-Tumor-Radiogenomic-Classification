{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **RSNA-MICCAI Brain Tumor Radiogenomic Classification**\n**Predict the status of a genetic biomarker important for brain cancer treatment**","metadata":{}},{"cell_type":"markdown","source":"# **Imports and variable declarations**\n\nThis section contains the libraries used in the notebook as well as the variables relating to the parameters of the generated network.","metadata":{}},{"cell_type":"code","source":"import os # os functionalities\nimport re # regular expressions\nimport warnings # avoid tf warnings\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nfrom skimage import io # image manipulation\nimport seaborn as sns # heatmap visualization\nfrom matplotlib import pyplot as plt # image visualization\nwarnings.filterwarnings('ignore') # ignore tensorflow warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore tensorflow warnings\n\n# Tensorflow & Keras & SkLearn\nimport keras\nimport tensorflow as tf \nfrom tensorflow.keras.metrics import AUC # area under ROC\nfrom keras.applications.vgg16 import VGG16 # pretrained model\nfrom sklearn.model_selection import train_test_split # divide dataset\nfrom tensorflow.keras.preprocessing import image # preprocess a read image\nfrom sklearn.metrics import confusion_matrix # metrics for assesing the model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variable declaration\n'''\nImages for an specific patient are selected following one of these criteria\n    - central: Since all the images of the same patient are ordered by their id, the one in the middle is seletected\n    - first: Select the first one to appear\n    - all: Select all the available images for a given patient\n'''\npatient_mode = \"all\" # all - central - first \nimage_modes = [\"FLAIR\"] # FLAIR - T1w - T1wCE - T2w\n\n# Paths to images\ninput_dir = \"../input/rsna-miccai-png/train\" \ntarget_dir = \"../input/rsna-miccai-png/test\"\n\n# Model variables\nepochs = 40\nbatch_size = 32\nlearning_rate = 0.0005\noptimizer = \"RMSprop\"\ndata_augmentation = False\nloss_function = \"binary_crossentropy\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data loading**","metadata":{}},{"cell_type":"code","source":"def prepare_data(image_mode, patient_mode):\n    \"\"\"\n    This function prepares the paths to the images and gets the labels for each image\n    :parameter image_mode: Type of the images to be loaded (FLAIR - T1w - T1wCE - T2w)\n    :parameter patient_mode: Criteria for selecting the specific images of a patient that are going to be used\n    :return input_img_paths: List of paths to the images\n    :return labels: List of labels for each image\n    \"\"\"\n\n    # Get path to the training images\n    input_img_paths_patients = sorted([\n        os.path.join(input_dir, fname + \"/\" + image_mode) \n        for fname in os.listdir(input_dir)\n        if os.path.exists(os.path.join(input_dir, fname + \"/\" + image_mode))])\n\n    # Get images id's by a specific criteria\n    input_img_paths = []\n    for patient in input_img_paths_patients:\n        images_id = x = [int(re.findall(r'\\d+', x)[0]) for x in os.listdir(patient)] # Get all image ids\n        '''\n        Images for an specific patient are selected following one of these criteria\n        - central: Since all the images of the same patient are ordered by their id, the one in the middle is seletected\n        - first: Select the first one to appear\n        - all: Select all the available images for a given patient\n        '''\n        if patient_mode == \"central\":  # Get middle image\n            index_central_image = min(images_id) + round((max(images_id) - min(images_id))/2)\n            path = os.path.join(patient, \"Image-\" + str(index_central_image) + \".png\")\n            if os.path.exists(path): input_img_paths.append(path)\n        if patient_mode == \"first\": # Get first image\n            index_central_image = min(images_id) \n            path = os.path.join(patient, \"Image-\" + str(index_central_image) + \".png\")\n            if os.path.exists(path): input_img_paths.append(path)\n        if patient_mode == 'all': # Add all of the available images\n            for image in images_id:\n                path = os.path.join(patient, \"Image-\" + str(image) + \".png\")\n                if os.path.exists(path): input_img_paths.append(path)\n\n    # Read csv labels\n    df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\n\n    # Obtain pure labels\n    labels = []\n    for img_path in input_img_paths:\n        labels.append(df.loc[df['BraTS21ID'] == int(re.findall(r'\\d+', img_path)[0])]['MGMT_value'].iloc[0])\n        \n    return input_img_paths, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_data(input_img_paths, labels, verbose=True):\n    \"\"\"\n    This function splits the data between the training, validation and test sets\n    :parameter input_img_paths: List of paths to the images\n    :parameter labels: List of labels for each image\n    :return train_df: Dataframe containing paths and labels of the training set\n    :return val_df: Dataframe containing paths and labels of the validation set\n    :return test_df: Dataframe containing paths and labels of the test set\n    \"\"\"\n    \n    # Split data into train, validation and test\n    X_train, X_test, y_train, y_test = train_test_split(input_img_paths, labels, test_size=0.1, random_state=42)\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.111, random_state=42) # 0.111*0.9 = 0.1\n\n    # Check amounts of data in each split\n    if verbose:\n        print(f\"Training samples: {str(len(X_train))}\\nValidation samples: {str(len(X_val))}\\nTest samples: {str(len(X_test))}\\n\")\n\n    # Create dataframes for keras flow_from_dataframe\n    data = {'id': X_train, 'label': [str(x) for x in y_train]}\n    train_df = pd.DataFrame(data)\n\n    data = {'id': X_val, 'label': [str(x) for x in y_val]}\n    val_df = pd.DataFrame(data)\n\n    data = {'id': X_test, 'label': [str(x) for x in y_test]}\n    test_df = pd.DataFrame(data)\n    \n    return train_df, val_df, test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_generators(train_df, val_df, test_df, data_augmentation=False):\n    \"\"\"\n    This function loads the dataset from dataset folder and returns the image generators associated\n    :parameter train_df: Dataframe with paths to training images and labels\n    :parameter val_df: Dataframe with paths to validation images and labels\n    :parameter test_df: Dataframe with paths to test images and labels\n    :parameter data_augmentation: Boolean indicating whether to include or not data augmentation\n    :return train_generator: Training generator\n    :return val_generator: Validation generator\n    :return test_generator: Testing generator\n    \"\"\"\n\n    # Create a data generator\n    if data_augmentation:\n        datagen_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0,\n                                                                        rotation_range=20,\n                                                                        width_shift_range=0.1,\n                                                                        height_shift_range=0.1,\n                                                                        zoom_range=0.2,\n                                                                        horizontal_flip=True)\n    else:\n        datagen_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n        \n    datagen_val_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n\n    # Load and iterate training dataset\n    train_generator=datagen_train.flow_from_dataframe(dataframe=train_df, x_col=\"id\", y_col=\"label\", \n                                                      class_mode=\"binary\", batch_size=batch_size, target_size=(224, 224))\n    # Load and iterate validation dataset\n    val_generator=datagen_val_test.flow_from_dataframe(dataframe=val_df, x_col=\"id\", y_col=\"label\", \n                                                       class_mode=\"binary\", batch_size=batch_size, target_size=(224, 224))\n    # Load and iterate test dataset\n    test_generator=datagen_val_test.flow_from_dataframe(dataframe=test_df, x_col=\"id\", y_col=\"label\", \n                                                        class_mode=\"binary\", batch_size=batch_size, target_size=(224, 224))\n\n    return train_generator, val_generator, test_generator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(image_mode, patient_mode, data_augmentation):\n    \"\"\"\n    This function loads the dataset for a given image mode\n    :parameter image_mode: Type of the images to be loaded (FLAIR - T1w - T1wCE - T2w)\n    :parameter patient_mode: Criteria for selecting the specific images of a patient that are going to be used\n    :parameter data_augmentation: Boolean indicating whether to include or not data augmentation\n    :return train_generator: Training generator\n    :return val_generator: Validation generator\n    :return test_generator: Testing generator\n    \"\"\"\n    \n    input_img_paths, labels = prepare_data(image_mode, patient_mode)\n    train_df, val_df, test_df = split_data(input_img_paths, labels)\n    train_generator, val_generator, test_generator = get_data_generators(train_df, val_df, test_df, data_augmentation)\n    \n    return train_generator, val_generator, test_generator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data visualization**","metadata":{}},{"cell_type":"code","source":"for visualization in [\"T2w\"]:\n\n    # Load images\n    input_img_paths, labels = prepare_data(visualization, \"central\")\n    train_df, val_df, test_df = split_data(input_img_paths, labels, verbose=False)\n\n    samples = 3 # Number of samples to select of each label\n\n    # samples are obtained for no tumor and tumor\n    selected = pd.concat([train_df[train_df.label.eq('0')].sample(samples), train_df[train_df.label.eq('1')].sample(samples)])\n\n    # Create figure\n    fig = plt.figure(figsize=(20, 10))\n\n    # Setting values to rows and column variables\n    rows = 2\n    columns = samples\n\n    # Plot images\n    for element in range(0, len(selected)):\n        fig.add_subplot(rows, columns, element + 1)\n        plt.imshow(io.imread(list(selected['id'])[element]), cmap='gray')\n        plt.title(f\"Tumor presence: {list(selected['label'])[element]}\")\n        plt.savefig(f'{visualization}_visualization.pdf')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model definition**","metadata":{}},{"cell_type":"code","source":"def define_model(verbose=False):\n    \"\"\"\n    This function defines the convolutional neural network model to be used\n    :return train_generator: Training generator\n    \"\"\"\n    \n    # Free up RAM in case the model definition cells were run multiple times\n    keras.backend.clear_session()\n\n    # Build model\n    vgg16_weight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    base_model = VGG16(include_top=False, input_shape=(224, 224, 3), weights=vgg16_weight_path)\n    #base_model = VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n\n    # Make sure that the base_model is running in inference mode here, by passing `training=False`\n    base_model.trainable = False\n\n    # Define model structure\n    inputs = keras.Input(shape=(224, 224, 3))\n    x = base_model(inputs, training=False)\n    # Convert features of shape `base_model.output_shape[1:]` to vectors\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    # Dense classifier for binary classification\n    x = keras.layers.Dense(128, activation='relu')(x)\n    x = keras.layers.Dense(64, activation='relu')(x)\n    x = keras.layers.Dense(32, activation='relu')(x)\n    x = keras.layers.Dense(16, activation='relu')(x)\n    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n    model = keras.Model(inputs, outputs)\n    if verbose:\n        model.summary()\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose optimizer - SGD - RMSprop - Adam\nif optimizer == \"SGD\": \n    fit_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, decay=learning_rate/epochs)\nelif optimizer == \"RMSprop\":\n    fit_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate, decay=learning_rate/epochs)\nelse: \n    fit_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-7, amsgrad=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model training**","metadata":{}},{"cell_type":"code","source":"def train_model(model, fit_optimizer, loss_function, epochs, train_generator, val_generator, image_mode):\n    \"\"\"\n    This function trains a given model with the parameters specified the dataset for a given image mode\n    :parameter model: Keras model to be trained \n    :parameter fit_optimizer: Optimizers to compute the moving average and overwrite the model variables at desired time\n    :parameter loss_function: Objective function\n    :parameter epochs: Number of episodes to trained the model\n    :parameter training_generator: Training generator\n    :parameter val_generator: Validation generator\n    :parameter image_mode: Type of the images to be loaded (FLAIR - T1w - T1wCE - T2w)\n    :return model: Keras model trained\n    :return model_history: Model training history \n    \"\"\"\n    \n    # Free up RAM in case the model definition cells were run multiple times\n    keras.backend.clear_session()\n    \n    # Configure the model for training.\n    model.compile(optimizer=fit_optimizer, loss=loss_function, metrics=['accuracy', AUC()])\n\n    # Safe best model and Early Stopping\n    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)]\n\n    # Train the model, doing validation at the end of each epoch.\n    model_history = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=callbacks)\n    \n    return model, model_history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store models, scores, training histories and test generators into dictionaries\nmodels = {}\nscores = {}\nmodel_histories = {}\ntest_generators = {}\n\n# Train a model for each image_mode available\nfor image_mode in image_modes:\n    print(f\"\\nTraining with: {image_mode} images\\n\")\n    \n    # Prepare and load data\n    train_generator, val_generator, test_generator = load_dataset(image_mode, patient_mode, data_augmentation)\n\n    # Define model\n    model = define_model()\n\n    # Train model\n    model, model_histories[image_mode] = train_model(model, fit_optimizer, loss_function, epochs, train_generator, val_generator, image_mode)\n    models[image_mode] = model\n    \n    # Evaluate the model\n    test_generators[image_mode] = test_generator\n    test_generator.reset()\n    scores[image_mode] = model.evaluate(test_generator, verbose=0)\n    print(f\"\\nLoss: {str(scores[image_mode][0])} \\nAccuracy on test: {str(scores[image_mode][1])}\\nAUC: {str(scores[image_mode][2])}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model evaluation**","metadata":{}},{"cell_type":"code","source":"# Get best model\nbest_model = list(scores.keys())[0]\nfor image_mode in scores:\n    if scores[image_mode][2] > scores[best_model][2]:\n        best_model = image_mode\n        \n# Serialize and save model to json\nmodel_json = models[best_model].to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Serialize and save weights to HDF5\nmodels[best_model].save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy plot to show the evolution of the training process of the best model\nplt.figure(figsize=(7, 5), dpi=100)\nplt.plot(model_histories[best_model].history['accuracy'])\nplt.plot(model_histories[best_model].history['val_accuracy'])\nplt.title(f'Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.savefig(f'Brain_Tumor_accuracy.pdf')\nplt.show()\nplt.close()\n\n# Loss plot to show the evolution of the training process of the best model\nplt.figure(figsize=(7, 5), dpi=100)\nplt.plot(model_histories[best_model].history['loss'])\nplt.plot(model_histories[best_model].history['val_loss'])\nplt.title(f'Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.savefig(f'Brain_Tumor_loss.pdf')\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ntest_generators[best_model].reset()\nscore = models[best_model].evaluate(test_generators[best_model], verbose=0)\nprint(f\"Loss: {str(score[0])} \\nAccuracy on test: {str(score[1])}\\nAUC: {str(score[2])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign most probable label to predictions\ntest_generators[best_model].reset()\npred = models[best_model].predict(test_generators[best_model], verbose=0)\npredicted_class_indices = np.round(pred)\n\n# Get class labels\ntarget_names = (test_generators[best_model].class_indices).keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot confusion matrix\nfig, ax = plt.subplots(figsize=(10, 10), dpi=100)\ncf_matrix = confusion_matrix(np.array(test_generators[best_model].classes), predicted_class_indices)\nheatmap = sns.heatmap(cf_matrix/np.sum(cf_matrix), fmt='.2%', annot=True, cmap='Blues', cbar=True, square=False, \n                      annot_kws={\"fontsize\":32}, xticklabels=target_names, yticklabels=target_names)\nfig = heatmap.get_figure()\nplt.savefig(f'Brain_Tumor_confusion_matrix.pdf')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Challenge submission**","metadata":{}},{"cell_type":"code","source":"# Get path to the training images\ninput_img_paths_patients = sorted([\n    os.path.join(\"../input/rsna-miccai-png/test\", fname + \"/\" + \"FLAIR\") \n    for fname in os.listdir(\"../input/rsna-miccai-png/test\")\n    if os.path.exists(os.path.join(\"../input/rsna-miccai-png/test\", fname + \"/\" + \"FLAIR\"))])\n\n# Get images id's for central criteria\ninput_img_paths = []\nfor patient in input_img_paths_patients:\n    images_id = x = [int(re.findall(r'\\d+', x)[0]) for x in os.listdir(patient)] # Get all image ids\n    \n    # Get central image for patient\n    index_central_image = min(images_id) + round((max(images_id) - min(images_id))/2)\n    path = os.path.join(patient, \"Image-\" + str(index_central_image) + \".png\")\n    if os.path.exists(path): input_img_paths.append(path)\n\n# Make predictions\nresults = []\nfor img_input in input_img_paths:\n    img = image.load_img(img_input, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_batch = np.expand_dims(img_array, axis=0)\n    img_batch *= 255.0/img_batch.max() \n    results.append(models[best_model].predict(img_batch, verbose=0)[0][0])\n\n# Store predictions in suitable format for the challenge submission\nsubm = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\nsubm['MGMT_value'] = results\nsubm.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}